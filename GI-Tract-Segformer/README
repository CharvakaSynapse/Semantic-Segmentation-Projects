# Transformer vs CNN in GI Tract Segmentation: A Practical & Theoretical Study

This project benchmarks **SegFormer** (Transformer-based) and **U-Net** (CNN-based) architectures for medical image segmentation on the **GI Tract dataset**. The focus is on classifying anatomical structures like the **small bowel** — notoriously challenging due to its elongated, tubular morphology.

Both models were trained from scratch with identical data splits, augmentations, and evaluation logic. A comprehensive theory PDF explains why Transformers shine in such tasks.

---

### 🧪 Models Compared

1. **U-Net**  
   A CNN-based encoder–decoder segmentation model, widely used in biomedical imaging.

2. **SegFormer**  
   A lightweight Transformer-based semantic segmentation architecture from NVIDIA, accessed via HuggingFace.

---

### 📈 Quantitative Results (Small Bowel - Class 2)

| Metric (↑ better unless noted) | SegFormer | U-Net | Δ (S−U) |
|-------------------------------|-----------|-------|--------|
| Dice                          | **0.877** | 0.820 | +0.058 |
| HD95 (px) ↓                   | **5.914** | 11.177 | -5.263 |
| ASD (px) ↓                    | **1.550** | 2.653 | -1.103 |
| Surface Dice @2 px           | **0.865** | 0.783 | +0.081 |
| Object-F1                     | **0.842** | 0.724 | +0.117 |
| clDice                        | **0.875** | 0.815 | +0.060 |

📊 Full evaluation results (macro-averages, all 3 classes) available in `gi_seg_eval_summary.csv`

---

### 🔍 Key Insights

- **🧠 Global Attention Wins:** Transformers capture long-range dependencies critical for thin, connected structures like the small bowel.
- **💡 Continuity Matters:** SegFormer consistently outperforms U-Net on object-level and surface-aware metrics.
- **🧪 Metric Diversity:** Beyond Dice, we used HD95, ASD, clDice, and Surface Dice to evaluate edge quality, topology, and false contours.
- **📄 Theory Included:** PDF included explaining why CNNs struggle on tubular shapes (local inductive bias), while ViTs adapt better.

---

### 🚀 Usage

```bash
# Train U-Net
python unet.py

# Train SegFormer
python segformer.py

# Launch TensorBoard
tensorboard --logdir=tb_logs
```

Models log to `tb_logs/`, and inference results (visual overlays) go to `inference_results/`.

---

### 📁 Files Included

- `unet.py` – U-Net segmentation pipeline
- `segformer.py` – SegFormer HuggingFace fine-tuning
- `gi_seg_eval_summary.csv` – Metric table (class-wise + average)
- `segformer-cnn-segmentation-v4.pdf` – Theoretical write-up

---

### 📦 Dependencies

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install lightning transformers albumentations torchmetrics scikit-image scipy matplotlib
```

---

### 🧠 Citation

> Theoretical Framework for CNN vs Transformer Performance in Medical Segmentation: An Information-Geometric Analysis (2025)

---


