# Transformer vs CNN in GI Tract Segmentation: A Practical & Theoretical Study

This project benchmarks **SegFormer** (Transformer-based) and **U-Net** (CNN-based) architectures for medical image segmentation on the **GI Tract dataset**. The focus is on classifying anatomical structures like the **small bowel** â€” notoriously challenging due to its elongated, tubular morphology.

Both models were trained from scratch with identical data splits, augmentations, and evaluation logic. A comprehensive theory PDF explains why Transformers shine in such tasks.

---

### ðŸ§ª Models Compared

1. **U-Net**  
   A CNN-based encoderâ€“decoder segmentation model, widely used in biomedical imaging.

2. **SegFormer**  
   A lightweight Transformer-based semantic segmentation architecture from NVIDIA, accessed via HuggingFace.

---

### ðŸ“ˆ Quantitative Results (Small Bowel - Class 2)

| Metric (â†‘ better unless noted) | SegFormer | U-Net | Î” (Sâˆ’U) |
|-------------------------------|-----------|-------|--------|
| Dice                          | **0.877** | 0.820 | +0.058 |
| HD95 (px) â†“                   | **5.914** | 11.177 | -5.263 |
| ASD (px) â†“                    | **1.550** | 2.653 | -1.103 |
| Surface Dice @2 px           | **0.865** | 0.783 | +0.081 |
| Object-F1                     | **0.842** | 0.724 | +0.117 |
| clDice                        | **0.875** | 0.815 | +0.060 |

ðŸ“Š Full evaluation results (macro-averages, all 3 classes) available in `gi_seg_eval_summary.csv`

---

### ðŸ” Key Insights

- **ðŸ§  Global Attention Wins:** Transformers capture long-range dependencies critical for thin, connected structures like the small bowel.
- **ðŸ’¡ Continuity Matters:** SegFormer consistently outperforms U-Net on object-level and surface-aware metrics.
- **ðŸ§ª Metric Diversity:** Beyond Dice, we used HD95, ASD, clDice, and Surface Dice to evaluate edge quality, topology, and false contours.
- **ðŸ“„ Theory Included:** PDF included explaining why CNNs struggle on tubular shapes (local inductive bias), while ViTs adapt better.

---

### ðŸš€ Usage

```bash
# Train U-Net
python unet.py

# Train SegFormer
python segformer.py

# Launch TensorBoard
tensorboard --logdir=tb_logs
```

Models log to `tb_logs/`, and inference results (visual overlays) go to `inference_results/`.

---

### ðŸ“ Files Included

- `unet.py` â€“ U-Net segmentation pipeline
- `segformer.py` â€“ SegFormer HuggingFace fine-tuning
- `gi_seg_eval_summary.csv` â€“ Metric table (class-wise + average)
- `segformer-cnn-segmentation-v4.pdf` â€“ Theoretical write-up

---

### ðŸ“¦ Dependencies

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install lightning transformers albumentations torchmetrics scikit-image scipy matplotlib
```

---

### ðŸ§  Citation

> Theoretical Framework for CNN vs Transformer Performance in Medical Segmentation: An Information-Geometric Analysis (2025)

---


